{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af0b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain openai chromadb pandas tiktoken ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb02061",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e515fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade google-generativeai google-ai-generativelanguage langchain-google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29d44b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f958ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.5\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "print(genai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb27870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-robotics-er-1.5-preview\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=\"AIzaSyDY13i7wF-alG2sCos1BfeO2uxqt8A0OtM\")\n",
    "\n",
    "for m in genai.list_models():\n",
    "    if \"generateContent\" in m.supported_generation_methods:\n",
    "        print(m.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b821f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import pandas as pd, os\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Convert_system_message_to_human will be deprecated\")\n",
    "\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDY13i7wF-alG2sCos1BfeO2uxqt8A0OtM\"  # ÊõøÊç¢ÁúüÂÆû key\n",
    "data = pd.read_csv(\"data/holidays_events.csv\")\n",
    "\n",
    "def query_data(_input: str = \"\"):\n",
    "    \"\"\"Query the dataset: supports 'average' and 'count'.\"\"\"\n",
    "    q = _input.lower()\n",
    "    if \"average\" in q:\n",
    "        return str(data.mean(numeric_only=True))\n",
    "    elif \"count\" in q:\n",
    "        return f\"The dataset has {len(data)} entries.\"\n",
    "    else:\n",
    "        return \"Only average and count queries are supported.\"\n",
    "    \n",
    "def load_data(_input: str = \"\"): \n",
    "    train = pd.read_csv(\"data/train.csv\")\n",
    "    test = pd.read_csv(\"data/test.csv\")\n",
    "    oil = pd.read_csv(\"data/oil.csv\")\n",
    "    stores = pd.read_csv(\"data/stores.csv\")\n",
    "    holidays = pd.read_csv(\"data/holidays_events.csv\")\n",
    "    return \"‚úÖ Data loaded successfully: train={}, test={}, oil={}, stores={}, holidays={}\".format(\n",
    "        len(train), len(test), len(oil), len(stores), len(holidays)\n",
    "    )\n",
    "\n",
    "\n",
    "def create_features(_input: str = \"\"):\n",
    "    train = pd.read_csv(\"data/train.csv\")\n",
    "    oil = pd.read_csv(\"data/oil.csv\")\n",
    "    stores = pd.read_csv(\"data/stores.csv\")\n",
    "    holidays = pd.read_csv(\"data/holidays_events.csv\")\n",
    "\n",
    "    holidays = holidays.rename(columns={\n",
    "        \"type\": \"holiday_type\",\n",
    "        \"locale\": \"holiday_locale\",\n",
    "        \"locale_name\": \"holiday_locale_name\",\n",
    "        \"description\": \"holiday_description\",\n",
    "        \"transferred\": \"holiday_transferred\"\n",
    "    })\n",
    "\n",
    "    df = train.merge(stores, on=\"store_nbr\", how=\"left\")\n",
    "    df = df.merge(oil, on=\"date\", how=\"left\")\n",
    "    df = df.merge(holidays, on=\"date\", how=\"left\")\n",
    "\n",
    "    df[\"dayofweek\"] = pd.to_datetime(df[\"date\"]).dt.dayofweek\n",
    "    df.to_csv(\"data/merged.csv\", index=False)\n",
    "    return \"‚úÖ Features created and saved to data/merged.csv\"\n",
    "\n",
    "\n",
    "def forecast_sales(_input: str = \"\"):\n",
    "    \"\"\"Trend-aware sales forecasting with smooth predictions.\"\"\"\n",
    "    df = pd.read_csv(\"data/merged.csv\")\n",
    "\n",
    "    match_store = re.search(r\"store\\s*=?\\s*(\\d+)\", _input)\n",
    "    match_family = re.search(r\"family\\s*=?\\s*'?([A-Za-z_]+)'?\", _input)\n",
    "    match_period = re.search(r\"periods\\s*=?\\s*(\\d+)\", _input)\n",
    "\n",
    "    store_nbr = int(match_store.group(1)) if match_store else 10\n",
    "    family = match_family.group(1).upper() if match_family else \"BEVERAGES\"\n",
    "    periods = int(match_period.group(1)) if match_period else 15\n",
    "\n",
    "    df = df[(df[\"store_nbr\"] == store_nbr) & (df[\"family\"].str.upper() == family)].copy()\n",
    "    if df.empty:\n",
    "        return f\"‚ö†Ô∏è No matching records found for store {store_nbr}, family '{family}'.\"\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df = df.sort_values(\"date\")\n",
    "\n",
    "    for col in [\"onpromotion\", \"dcoilwtico\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(0)\n",
    "        else:\n",
    "            df[col] = 0\n",
    "\n",
    "    if \"sales_ma7\" not in df.columns:\n",
    "        df[\"sales_ma7\"] = (\n",
    "            df.groupby([\"store_nbr\", \"family\"])[\"sales\"]\n",
    "            .transform(lambda x: x.rolling(7, min_periods=1).mean())\n",
    "        )\n",
    "    df[\"sales_ma7\"] = df[\"sales_ma7\"].fillna(df[\"sales\"].mean())\n",
    "\n",
    "    df[\"time_index\"] = (df[\"date\"] - df[\"date\"].min()).dt.days\n",
    "    df[\"month\"] = df[\"date\"].dt.month\n",
    "    df[\"quarter\"] = df[\"date\"].dt.quarter\n",
    "    df[\"dayofweek\"] = df[\"date\"].dt.dayofweek\n",
    "    df[\"sin_day\"] = np.sin(2 * np.pi * df[\"dayofweek\"] / 7)\n",
    "    df[\"cos_day\"] = np.cos(2 * np.pi * df[\"dayofweek\"] / 7)\n",
    "    df[\"trend\"] = np.linspace(0, 1, len(df))\n",
    "    if \"holiday_type\" in df.columns:\n",
    "        df[\"is_holiday\"] = df[\"holiday_type\"].notna().astype(int)\n",
    "    else:\n",
    "        df[\"is_holiday\"] = 0\n",
    "\n",
    "    features = [\"onpromotion\", \"dcoilwtico\", \"time_index\", \"month\", \"quarter\",\n",
    "                \"is_holiday\", \"sales_ma7\", \"sin_day\", \"cos_day\", \"trend\"]\n",
    "\n",
    "    df = df.dropna(subset=features + [\"sales\"])\n",
    "    if df.empty:\n",
    "        return \"‚ö†Ô∏è All rows dropped after removing NaNs; not enough data to train model.\"\n",
    "\n",
    "    print(\"‚úÖ Non-empty training rows:\", len(df))\n",
    "    print(\"‚úÖ Missing values per feature:\\n\", df[features].isna().sum())\n",
    "\n",
    "    X = df[features]\n",
    "    y = np.log1p(df[\"sales\"])\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=300, max_depth=6, learning_rate=0.1, random_state=42\n",
    "    )\n",
    "    model.fit(X_scaled, y)\n",
    "    last_date = df[\"date\"].max()\n",
    "    future_dates = pd.date_range(last_date + pd.Timedelta(days=1), periods=periods)\n",
    "    future_df = pd.DataFrame({\n",
    "        \"date\": future_dates,\n",
    "        \"time_index\": np.arange(df[\"time_index\"].max() + 1,\n",
    "                                df[\"time_index\"].max() + 1 + periods),\n",
    "        \"month\": future_dates.month,\n",
    "        \"quarter\": future_dates.quarter,\n",
    "        \"onpromotion\": 0,\n",
    "        \"dcoilwtico\": df[\"dcoilwtico\"].iloc[-30:].mean(),\n",
    "        \"is_holiday\": 0\n",
    "    })\n",
    "    future_df[\"dayofweek\"] = future_dates.dayofweek\n",
    "    future_df[\"sin_day\"] = np.sin(2 * np.pi * future_df[\"dayofweek\"] / 7)\n",
    "    future_df[\"cos_day\"] = np.cos(2 * np.pi * future_df[\"dayofweek\"] / 7)\n",
    "    future_df[\"trend\"] = np.linspace(1, 1 + (periods / len(df)), periods)\n",
    "    last_sales = df[\"sales\"].iloc[-7:].values\n",
    "    future_df[\"sales_ma7\"] = np.mean(last_sales) * np.linspace(1, 1.05, periods)\n",
    "\n",
    "    X_future_scaled = scaler.transform(future_df[features])\n",
    "    pred = np.expm1(model.predict(X_future_scaled))\n",
    "    future_df[\"pred_sales\"] = np.clip(pred, 0, df[\"sales\"].max() * 1.3)\n",
    "    future_df[\"store_nbr\"] = store_nbr\n",
    "    future_df[\"family\"] = family\n",
    "\n",
    "    future_df.to_csv(\"data/pred_sales.csv\", index=False)\n",
    "    return f\"‚úÖ Forecast completed (smoothed) for store {store_nbr}, family '{family}', next {periods} days.\"\n",
    "\n",
    "def plot_forecast(_input: str = \"\"): \n",
    "    df = pd.read_csv(\"data/pred_sales.csv\")\n",
    "    plt.plot(df[\"date\"], df[\"pred_sales\"], label=\"predicted\")\n",
    "    plt.title(\"Forecasted Sales\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return \"‚úÖ Forecast plotted successfully.\"\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Data Query Tool\",\n",
    "        func=query_data,\n",
    "        description=\"Use this tool to explore the Kaggle dataset. Input: a query string such as 'average' or 'count'.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Load Data\",\n",
    "        func=load_data,\n",
    "        description=(\n",
    "            \"Load all CSV datasets including train, test, oil, stores, and holidays. \"\n",
    "            \"Use this before doing any feature analysis or modeling.\"\n",
    "        ),\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Feature Engineering\",\n",
    "        func=create_features,\n",
    "        description=(\n",
    "            \"Merge datasets and create time-based and contextual features such as dayofweek, oil price, and holidays. \"\n",
    "            \"Use this tool before training a model.\"\n",
    "        ),\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Forecast Model\",\n",
    "        func=forecast_sales,\n",
    "        description=(\n",
    "            \"Predict store sales using XGBoost. \"\n",
    "            \"‚öôÔ∏è Input format REQUIRED: store_nbr=<int>, family='<string>', periods=<int>. \"\n",
    "            \"Example: store_nbr=10, family='BEVERAGES', periods=15 \"\n",
    "            \"If you do not include Action Input, the forecast will not run correctly.\"\n",
    "        ),\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Plot Forecast\",\n",
    "        func=plot_forecast,\n",
    "        description=\"Visualize predicted sales results and display a simple chart of the forecast.\",\n",
    "    ),\n",
    "    PythonREPLTool(),\n",
    "]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0, convert_system_message_to_human=True)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "react_agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "response = react_agent.run(\"Predict sales for store 10 family 'BEVERAGES' for the next 7 days and show a chart.\")\n",
    "print(\"Final Answer:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "321a4d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.5-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\13649\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\13649\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.14.1)\n",
      "Downloading xgboost-3.0.5-py3-none-win_amd64.whl (56.8 MB)\n",
      "   ---------------------------------------- 0.0/56.8 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 8.9/56.8 MB 46.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 17.3/56.8 MB 43.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 28.6/56.8 MB 47.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 33.8/56.8 MB 41.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 44.8/56.8 MB 43.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.1/56.8 MB 45.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 56.8/56.8 MB 43.6 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee7d5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ submission.csv generated successfully for Kaggle upload!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_submission_from_all():\n",
    "    test_df = pd.read_csv(\"data/test.csv\")\n",
    "    pred_df = pd.read_csv(\"data/pred_sales_all.csv\")\n",
    "\n",
    "    merged = test_df.merge(\n",
    "        pred_df,\n",
    "        on=[\"date\", \"store_nbr\", \"family\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    merged[\"sales\"] = merged[\"pred_sales\"].fillna(0)\n",
    "\n",
    "    submission = merged[[\"id\", \"sales\"]]\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"‚úÖ submission.csv generated successfully for Kaggle upload!\")\n",
    "\n",
    "generate_submission_from_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f7b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def forecast_all_stores_and_families():\n",
    "    train = pd.read_csv(\"data/train.csv\")\n",
    "    test = pd.read_csv(\"data/test.csv\")\n",
    "    oil = pd.read_csv(\"data/oil.csv\")\n",
    "    stores = pd.read_csv(\"data/stores.csv\")\n",
    "    holidays = pd.read_csv(\"data/holidays_events.csv\")\n",
    "\n",
    "    holidays = holidays.rename(columns={\n",
    "        \"type\": \"holiday_type\",\n",
    "        \"locale\": \"holiday_locale\",\n",
    "        \"locale_name\": \"holiday_locale_name\",\n",
    "        \"description\": \"holiday_description\",\n",
    "        \"transferred\": \"holiday_transferred\"\n",
    "    })\n",
    "\n",
    "    def merge_features(df):\n",
    "        df = df.merge(stores, on=\"store_nbr\", how=\"left\")\n",
    "        df = df.merge(oil, on=\"date\", how=\"left\")\n",
    "        df = df.merge(holidays, on=\"date\", how=\"left\")\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df[\"dayofweek\"] = df[\"date\"].dt.dayofweek\n",
    "        df[\"month\"] = df[\"date\"].dt.month\n",
    "        df[\"quarter\"] = df[\"date\"].dt.quarter\n",
    "        df[\"sin_day\"] = np.sin(2 * np.pi * df[\"dayofweek\"] / 7)\n",
    "        df[\"cos_day\"] = np.cos(2 * np.pi * df[\"dayofweek\"] / 7)\n",
    "        df[\"is_holiday\"] = df[\"holiday_type\"].notna().astype(int)\n",
    "        return df\n",
    "\n",
    "    train = merge_features(train)\n",
    "    test = merge_features(test)\n",
    "    features = [\"onpromotion\",\"dcoilwtico\",\"dayofweek\",\"month\",\"quarter\",\"sin_day\",\"cos_day\",\"is_holiday\"]\n",
    "    submission_rows = []\n",
    "\n",
    "    families = sorted(train[\"family\"].unique())\n",
    "    stores_list = sorted(train[\"store_nbr\"].unique())\n",
    "\n",
    "    print(f\"üîπ Predicting for {len(families)} families √ó {len(stores_list)} stores\")\n",
    "\n",
    "    for fam in families:\n",
    "        train_fam = train[train[\"family\"] == fam].copy()\n",
    "        for store in stores_list:\n",
    "            tr = train_fam[train_fam[\"store_nbr\"] == store]\n",
    "            te = test[(test[\"family\"] == fam) & (test[\"store_nbr\"] == store)]\n",
    "            if tr.empty or te.empty:\n",
    "                continue\n",
    "            for c in features:\n",
    "                tr[c] = tr[c].fillna(0)\n",
    "                te[c] = te[c].fillna(0)\n",
    "\n",
    "            X_train = tr[features]\n",
    "            y_train = np.log1p(tr[\"sales\"])\n",
    "            X_test = te[features]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            model = XGBRegressor(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "\n",
    "            y_pred = np.expm1(model.predict(X_test_scaled))\n",
    "            y_pred = np.clip(y_pred, 0, None)\n",
    "\n",
    "            tmp = pd.DataFrame({\n",
    "                \"id\": te[\"id\"],\n",
    "                \"sales\": y_pred\n",
    "            })\n",
    "            submission_rows.append(tmp)\n",
    "\n",
    "    submission = pd.concat(submission_rows, ignore_index=True)\n",
    "    submission = submission.sort_values(\"id\")\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"‚úÖ submission.csv generated successfully, matching Kaggle format.\")\n",
    "    return \"‚úÖ Model Agent finished training and forecasting successfully. submission.csv ready.\"\n",
    "forecast_all_stores_and_families()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb29a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(_input=\"\"):\n",
    "    return load_data()\n",
    "\n",
    "def feature_builder(_input=\"\"):\n",
    "    return create_features()\n",
    "\n",
    "def forecaster(_input=\"\"):\n",
    "    return forecast_all_stores_and_families()\n",
    "\n",
    "def evaluator(_input=\"\"):\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import mean_squared_log_error\n",
    "    df = pd.read_csv(\"data/merged.csv\")\n",
    "    pred = pd.read_csv(\"submission.csv\")\n",
    "    y_true = df[\"sales\"].clip(lower=0)\n",
    "    y_pred = np.clip(y_true * np.random.uniform(0.9, 1.1, len(y_true)), 0, None)\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    return f\"‚úÖ RMSLE simulated: {rmsle:.4f}\"\n",
    "\n",
    "mcp_tools = [\n",
    "    Tool(name=\"Data Agent\", func=data_loader, description=\"Ë¥üË¥£Âä†ËΩΩÊâÄÊúâÊï∞ÊçÆÊñá‰ª∂\"),\n",
    "    Tool(name=\"Feature Agent\", func=feature_builder, description=\"Ë¥üË¥£ÁâπÂæÅÂ∑•Á®ã‰∏éÊï∞ÊçÆÊ∏ÖÊ¥ó\"),\n",
    "    Tool(name=\"Model Agent\", func=forecaster, description=\"ËÆ≠ÁªÉÂíåÈ¢ÑÊµãÊâÄÊúâ store + family\"),\n",
    "    Tool(name=\"Evaluation Agent\", func=evaluator, description=\"ËÆ°ÁÆó RMSLE ËØÑ‰º∞Ê®°ÂûãË°®Áé∞\")\n",
    "]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "mcp_agent = initialize_agent(\n",
    "    tools=mcp_tools,\n",
    "    llm=llm,\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "response = mcp_agent.run(\n",
    "    \"Load all datasets, build features, train models for all stores and families, evaluate RMSLE, and generate the final submission file.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1af48979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting self-healing ReAct agent...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the `generate_tool_from_task` tool to create a forecasting solver for the Favorita sales forecasting task on Kaggle. The task involves predicting sales for various product families in different stores in Ecuador, considering factors like store information, promotions, oil prices, and holidays/events. After generating the tool, I will test it using the `solve()` function.\n",
      "Action: generate_tool_from_task\n",
      "Action Input: Predict sales for the thousands of product families sold at Favorita stores located in Ecuador. The training data includes dates, store and product information, whether that item was being promoted, as well as the sales numbers. Additional files include supplementary information that may be useful in building your models.\n",
      "File Descriptions and Data Field Information\n",
      "train.csv\n",
      "The training data, comprising time series of features store_nbr, family, and onpromotion as well as the target sales.\n",
      "store_nbr identifies the store at which the products are sold.\n",
      "family identifies the type of product sold.\n",
      "sales gives the total sales for a product family at a particular store at a given date. Fractional values are possible since products can be sold in fractional units (1.5 kg of cheese, for instance, as opposed to 1 bag of chips).\n",
      "onpromotion gives the total number of items in a product family that were being promoted at a store at a given date.\n",
      "test.csv\n",
      "The test data, having the same features as the training data. You will predict the target sales for the dates in this file.\n",
      "The dates in the test data are for the 15 days after the last date in the training data.\n",
      "sample_submission.csv\n",
      "A sample submission file in the correct format.\n",
      "stores.csv\n",
      "Store metadata, including city, state, type, and cluster.\n",
      "cluster is a grouping of similar stores.\n",
      "oil.csv\n",
      "Daily oil price. Includes values during both the train and test data timeframes. (Ecuador is an oil-dependent country and it's economical health is highly vulnerable to shocks in oil prices.)\n",
      "holidays_events.csv\n",
      "Holidays and Events, with metadata\n",
      "NOTE: Pay special attention to the transferred column. A holiday that is transferred officially falls on that calendar day, but was moved to another date by the government. A transferred day is more like a normal day than a holiday. To find the day that it was actually celebrated, look for the corresponding row where type is Transfer. For example, the holiday Independencia de Guayaquil was transferred from 2012-10-09 to 2012-10-12, which means it was celebrated on 2012-10-12. Days that are type Bridge are extra days that are added to a holiday (e.g., to extend the break across a long weekend). These are frequently made up by the type Work Day which is a day not normally scheduled for work (e.g., Saturday) that is meant to payback the Bridge.\n",
      "Additional holidays are days added a regular calendar holiday, for example, as typically happens around Christmas (making Christmas Eve a holiday).\n",
      "Additional Notes\n",
      "Wages in the public sector are paid every two weeks on the 15 th and on the last day of the month. Supermarket sales could be affected by this.\n",
      "A magnitude 7.8 earthquake struck Ecuador on April 16, 2016. People rallied in relief efforts donating water and other first need products which greatly affected supermarket sales for several weeks after the earthquake.\u001b[0müß© Generated Code Preview:\n",
      " import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "def solve():\n",
      "    train = pd.read_csv(\"data/train.csv\", parse_dates=['date'])\n",
      "    test = pd.read_csv(\"data/test.csv\", parse_dates=['date'])\n",
      "    oil = pd.read_csv(\"data/oil.csv\", parse_dates=['date'])\n",
      "    stores = pd.read_csv(\"data/stores.csv\")\n",
      "    holidays = pd.r \n",
      "----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "<string>:58: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "<string>:59: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Attempt 1 failed, auto-fixing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised TooManyRequests: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Fixed Code Preview:\n",
      " import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "def solve():\n",
      "    train = pd.read_csv(\"data/train.csv\", parse_dates=['date'])\n",
      "    test = pd.read_csv(\"data/test.csv\", parse_dates=['date'])\n",
      "    oil = pd.read_csv(\" \n",
      "----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "<string>:59: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "<string>:60: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Attempt 2 failed, auto-fixing...\n",
      "üîß Fixed Code Preview:\n",
      " import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "def solve():\n",
      "    train = pd.read_csv(\"data/train.csv\", parse_dates=['date'])\n",
      "    test = pd.read_csv(\"data/test.csv\", parse_dates=['date'])\n",
      "    oil = pd.read_csv(\" \n",
      "----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "<string>:62: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "<string>:63: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Attempt 3 failed, auto-fixing...\n",
      "üîß Fixed Code Preview:\n",
      " import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "def solve():\n",
      "    train = pd.read_csv(\"data/train.csv\", parse_dates=['date'])\n",
      "    test = pd.read_csv(\"data/test.csv\", parse_dates=['date'])\n",
      "    oil = pd.read_csv(\" \n",
      "----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "<string>:55: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "<string>:56: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m‚ùå Failed after 3 repair attempts:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\13649\\AppData\\Local\\Temp\\ipykernel_75204\\230245548.py\", line 64, in try_execute\n",
      "    result = solve_fn()\n",
      "             ^^^^^^^^^^\n",
      "  File \"<string>\", line 58, in solve\n",
      "  File \"c:\\Users\\13649\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\", line 170, in merge\n",
      "    op = _MergeOperation(\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\13649\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\", line 807, in __init__\n",
      "    self._maybe_coerce_merge_keys()\n",
      "  File \"c:\\Users\\13649\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\", line 1512, in _maybe_coerce_merge_keys\n",
      "    raise ValueError(msg)\n",
      "ValueError: You are trying to merge on datetime64[ns] and object columns for key 'date'. If you wish to proceed you should use pd.concat\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe tool failed to execute because of a merge error between datetime64[ns] and object columns. This likely means the 'date' column has different data types in the dataframes being merged. I need to investigate the generated code and fix the data type mismatch before running the solve function again. I will examine the generated code to identify the merge operation causing the error and ensure the 'date' columns have the same data type. Since I don't have access to the generated code, I will regenerate the tool with the instruction to convert the date columns to the same type before merging.\n",
      "Action: generate_tool_from_task\n",
      "Action Input: Predict sales for the thousands of product families sold at Favorita stores located in Ecuador. The training data includes dates, store and product information, whether that item was being promoted, as well as the sales numbers. Additional files include supplementary information that may be useful in building your models. Ensure that before merging any dataframes on the 'date' column, convert the 'date' column to the same datetime64[ns] data type in all dataframes.\n",
      "File Descriptions and Data Field Information\n",
      "train.csv\n",
      "The training data, comprising time series of features store_nbr, family, and onpromotion as well as the target sales.\n",
      "store_nbr identifies the store at which the products are sold.\n",
      "family identifies the type of product sold.\n",
      "sales gives the total sales for a product family at a particular store at a given date. Fractional values are possible since products can be sold in fractional units (1.5 kg of cheese, for instance, as opposed to 1 bag of chips).\n",
      "onpromotion gives the total number of items in a product family that were being promoted at a store at a given date.\n",
      "test.csv\n",
      "The test data, having the same features as the training data. You will predict the target sales for the dates in this file.\n",
      "The dates in the test data are for the 15 days after the last date in the training data.\n",
      "sample_submission.csv\n",
      "A sample submission file in the correct format.\n",
      "stores.csv\n",
      "Store metadata, including city, state, type, and cluster.\n",
      "cluster is a grouping of similar stores.\n",
      "oil.csv\n",
      "Daily oil price. Includes values during both the train and test data timeframes. (Ecuador is an oil-dependent country and it's economical health is highly vulnerable to shocks in oil prices.)\n",
      "holidays_events.csv\n",
      "Holidays and Events, with metadata\n",
      "NOTE: Pay special attention to the transferred column. A holiday that is transferred officially falls on that calendar day, but was moved to another date by the government. A transferred day is more like a normal day than a holiday. To find the day that it was actually celebrated, look for the corresponding row where type is Transfer. For example, the holiday Independencia de Guayaquil was transferred from 2012-10-09 to 2012-10-12, which means it was celebrated on 2012-10-12. Days that are type Bridge are extra days that are added to a holiday (e.g., to extend the break across a long weekend). These are frequently made up by the type Work Day which is a day not normally scheduled for work (e.g., Saturday) that is meant to payback the Bridge.\n",
      "Additional holidays are days added a regular calendar holiday, for example, as typically happens around Christmas (making Christmas Eve a holiday).\n",
      "Additional Notes\n",
      "Wages in the public sector are paid every two weeks on the 15 th and on the last day of the month. Supermarket sales could be affected by this.\n",
      "A magnitude 7.8 earthquake struck Ecuador on April 16, 2016. People rallied in relief efforts donating water and other first need products which greatly affected supermarket sales for several weeks after the earthquake.\u001b[0müß© Generated Code Preview:\n",
      " import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.preprocessing import LabelEncoder\n",
      "\n",
      "def solve():\n",
      "    train = pd.read_csv(\"data/train.csv\")\n",
      "    test = pd.read_csv(\"data/test.csv\")\n",
      "    oil = pd.read_csv(\"data/oil.csv\")\n",
      "    stores = pd.read_csv(\"data/stores.csv\")\n",
      "    holidays = pd.read_csv(\"data/holidays_events.csv\")\n",
      "\n",
      "    train['date'] = pd.to_dat \n",
      "----------------------\n",
      "‚úÖ submission.csv created successfully at data/submission.csv\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m‚úÖ Tool created, verified, and submission.csv saved successfully.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe tool was successfully created and verified. Now I need to test it by running the `solve()` function.\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "print(solve())\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mNameError(\"name 'solve' is not defined\")\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI made a mistake. The `solve()` function is not available in the Python REPL. The `generate_tool_from_task` tool creates a standalone tool, and I don't have direct access to its functions within this environment. The tool has already been verified and saved the submission.csv, so it has run successfully.\n",
      "Final Answer: The tool was successfully created, verified, and the submission.csv file was saved. I was unable to directly call the solve() function from this environment.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, glob, pandas as pd, traceback\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "\n",
    "# ==========================\n",
    "#  STEP 1: ÁéØÂ¢ÉÂàùÂßãÂåñ\n",
    "# ==========================\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"‚ùå GOOGLE_API_KEY not found in .env file\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.2,\n",
    "    google_api_key=api_key,\n",
    "    transport=\"rest\",\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "#  STEP 2: ÁîüÊàê + Ëá™Êàë‰øÆÂ§ç Tool\n",
    "# ==========================\n",
    "def generate_tool_from_task(task_desc: str):\n",
    "    \"\"\"LLM Ëá™Âä®ÁîüÊàê„ÄÅÊâßË°åÂπ∂È™åËØÅ solve() ÂáΩÊï∞ÔºõÂ§±Ë¥•Êó∂Â∞ùËØïËá™Êàë‰øÆÂ§ç\"\"\"\n",
    "    import re, json, pandas as pd, glob, traceback\n",
    "\n",
    "    # --- Ëá™Âä®ËØªÂèñ CSV ÁªìÊûÑ ---\n",
    "    data_info = []\n",
    "    for f in glob.glob(\"data/*.csv\"):\n",
    "        try:\n",
    "            df = pd.read_csv(f)\n",
    "            data_info.append({\n",
    "                \"name\": f,\n",
    "                \"columns\": df.columns.tolist(),\n",
    "                \"rows\": len(df),\n",
    "                \"head\": df.head(2).to_dict(orient=\"records\")\n",
    "            })\n",
    "        except Exception as e:\n",
    "            data_info.append({\"name\": f, \"error\": str(e)})\n",
    "    data_summary = json.dumps(data_info, ensure_ascii=False, indent=2)\n",
    "\n",
    "    def clean_code(raw_code: str):\n",
    "        code = re.sub(r\"^```(python)?\", \"\", raw_code)\n",
    "        code = re.sub(r\"```$\", \"\", code)\n",
    "        code = \"\\n\".join(\n",
    "            line for line in code.splitlines()\n",
    "            if not line.strip().startswith(\"#\") and not line.lower().startswith(\"here\")\n",
    "        ).strip()\n",
    "        return code\n",
    "\n",
    "    def try_execute(code: str):\n",
    "        \"\"\"ÊâßË°å‰ª£Á†ÅÔºåÊ£ÄÊü• submission.csv ÊòØÂê¶ÁîüÊàê\"\"\"\n",
    "        namespace = {}\n",
    "        try:\n",
    "            exec(code, namespace)\n",
    "            solve_fn = namespace.get(\"solve\")\n",
    "            if not callable(solve_fn):\n",
    "                raise ValueError(\"No valid 'solve()' function defined.\")\n",
    "\n",
    "            result = solve_fn()\n",
    "            # ‚úÖ Ê£ÄÊü•ÊòØÂê¶ÁîüÊàê submission.csv\n",
    "            submission_path = \"data/submission.csv\"\n",
    "            if os.path.exists(submission_path):\n",
    "                print(f\"‚úÖ submission.csv created successfully at {submission_path}\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è submission.csv not found. The function may have failed to save it.\")\n",
    "                raise FileNotFoundError(\"submission.csv was not created.\")\n",
    "\n",
    "            return solve_fn, None\n",
    "        except Exception as e:\n",
    "            return None, traceback.format_exc()\n",
    "\n",
    "    # --- ÁîüÊàêÂàùÂßãÁâàÊú¨ ---\n",
    "    prompt = f\"\"\"\n",
    "You are an experienced Kaggle data scientist.\n",
    "\n",
    "Write a valid Python function named `solve()` that:\n",
    "1. Reads all CSVs from ./data (train.csv, test.csv, oil.csv, stores.csv, holidays_events.csv).\n",
    "2. Merges them properly by 'date', 'store_nbr', 'family'.\n",
    "3. Predicts the target `sales` for test.csv.\n",
    "4. Saves the predictions as a CSV file named `submission.csv` in ./data directory,\n",
    "   containing columns ['id', 'sales'].\n",
    "5. Return the DataFrame as the function output.\n",
    "\n",
    "Task description:\n",
    "{task_desc}\n",
    "\n",
    "Dataset preview:\n",
    "{data_summary}\n",
    "\n",
    "Rules:\n",
    "- Use pandas, numpy, sklearn, or xgboost.\n",
    "- Must call DataFrame.to_csv(\"data/submission.csv\", index=False) to save results.\n",
    "- Do not print() anything, only return the DataFrame.\n",
    "- Output ONLY the function code (no markdown or text).\n",
    "\"\"\"\n",
    "\n",
    "    code = llm.invoke(prompt).content\n",
    "    code = clean_code(code)\n",
    "    print(\"üß© Generated Code Preview:\\n\", code[:400], \"\\n----------------------\")\n",
    "\n",
    "    solve_fn, error = try_execute(code)\n",
    "    retry_count = 0\n",
    "\n",
    "    # --- Ëá™Êàë‰øÆÂ§çÂæ™ÁéØ ---\n",
    "    while error and retry_count < 3:\n",
    "        print(f\"‚ö†Ô∏è Attempt {retry_count+1} failed, auto-fixing...\")\n",
    "        fix_prompt = f\"\"\"\n",
    "The Python function below failed to create a valid submission.csv file.\n",
    "\n",
    "Error traceback:\n",
    "{error}\n",
    "\n",
    "Current code:\n",
    "{code}\n",
    "\n",
    "Please fix the code so that:\n",
    "- The 'solve()' function executes without errors.\n",
    "- It saves predictions as './data/submission.csv' (with ['id','sales'] columns).\n",
    "- Return the DataFrame as output.\n",
    "\n",
    "Only output valid Python code (no markdown).\n",
    "\"\"\"\n",
    "        fixed_code = llm.invoke(fix_prompt).content\n",
    "        fixed_code = clean_code(fixed_code)\n",
    "        print(\"üîß Fixed Code Preview:\\n\", fixed_code[:300], \"\\n----------------------\")\n",
    "\n",
    "        solve_fn, error = try_execute(fixed_code)\n",
    "        retry_count += 1\n",
    "        code = fixed_code\n",
    "\n",
    "    if error:\n",
    "        return f\"‚ùå Failed after {retry_count} repair attempts:\\n{error}\"\n",
    "\n",
    "    tools.append(\n",
    "        Tool(\n",
    "            name=\"auto_solve_task\",\n",
    "            func=lambda _: solve_fn(),\n",
    "            description=\"Auto-generated Kaggle forecasting solver that outputs submission.csv\"\n",
    "        )\n",
    "    )\n",
    "    return \"‚úÖ Tool created, verified, and submission.csv saved successfully.\"\n",
    "\n",
    "\n",
    "# ==========================\n",
    "#  STEP 3: ÂàùÂßãÂåñ Agent\n",
    "# ==========================\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"generate_tool_from_task\",\n",
    "        func=generate_tool_from_task,\n",
    "        description=\"Generate and test a forecasting tool based on a Kaggle dataset task.\"\n",
    "    ),\n",
    "    PythonREPLTool()\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "#  STEP 4: ËøêË°å‰∏ª‰ªªÂä°\n",
    "# ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    with open(\"data_description.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        task_desc = f.read()\n",
    "\n",
    "    print(\"üöÄ Starting self-healing ReAct agent...\")\n",
    "    agent.run(f\"\"\"\n",
    "Use generate_tool_from_task to build a forecasting solver using this Kaggle task:\n",
    "{task_desc}\n",
    "Then test it by running the generated solve() function.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
